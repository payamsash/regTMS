{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm.contrib.itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind, ttest_rel\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from mne import read_labels_from_annot\n",
    "from hyppo.ksample import KSample\n",
    "from mne.stats import f_mway_rm, fdr_correction\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataframe / define responders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load power in labels and add whole brain activation\n",
    "dfs_list = []\n",
    "folder_name = Path.cwd().parent / \"data\" / \"dataframes\" / \"powers\"\n",
    "for file in tqdm(sorted(os.listdir(folder_name))):\n",
    "    if file.endswith(\".csv\"):\n",
    "        fname = folder_name / file\n",
    "        df = pd.read_csv(fname, index_col=[0])\n",
    "        \n",
    "        ## add whole brain power\n",
    "        df1s_list = []\n",
    "        for frange in [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]:\n",
    "            for hemi in [\"lh\", \"rh\"]:\n",
    "                df1 = df[df[\"frequency_band\"] == frange]\n",
    "                df1 = df1[df1['brain_label'].str.contains(f'-{hemi}', case=False, na=False)]\n",
    "                power_hemi = df1[\"power\"].sum()\n",
    "                keys = list(df.columns)\n",
    "                values = [df1[key].unique()[0] for key in keys[:-2]]\n",
    "                values.append([f\"whole-{hemi}\"])\n",
    "                values.append([power_hemi])\n",
    "                new_row = dict(zip(keys, values))\n",
    "                df_new_row = pd.DataFrame(new_row)\n",
    "                df1 = pd.concat([df1, df_new_row])\n",
    "                df1s_list.append(df1)\n",
    "        df_updated = pd.concat(df1s_list)\n",
    "        dfs_list.append(df_updated)\n",
    "        \n",
    "dfs = pd.concat(dfs_list)\n",
    "df = dfs.reset_index().drop(columns=[\"index\", \"Unnamed: 0\"])\n",
    "\n",
    "## define responders and non responders\n",
    "subjects_to_drop_dict = {}\n",
    "prots = [\"1 Hz\", \"10 Hz\", \"20 Hz\"]\n",
    "hemis = [\"left\", \"right\"]\n",
    "all_combs = product(prots, hemis)\n",
    "for protocol, hemi in all_combs:\n",
    "    fname = \"/Users/payamsadeghishabestari/codes/regTMS/data/behavioral_data/TL_data.xlsx\"\n",
    "    df_tl = pd.read_excel(fname)\n",
    "    df_tl[\"protcol\"] = df_tl[\"protcol\"].replace(\"1Hz\", \"1 Hz\")\n",
    "    df_tl_sub = df_tl.query(f'protcol == \"{protocol}\" & hemisphere == \"{hemi}\"')\n",
    "    df_tl_sub['pre_avg'] = df_tl.filter(like='pre').mean(axis=1)\n",
    "    df_tl_sub['post_avg'] = df_tl.filter(like='post').mean(axis=1)\n",
    "    df_tl_sub[\"diff_TL\"] = df_tl_sub['pre_avg'] - df_tl_sub['post_avg']\n",
    "    df_tl_sub = df_tl_sub.rename(columns={'ID': 'subject_ID'})\n",
    "    df_tl_diff = df_tl_sub[[\"subject_ID\", \"diff_TL\"]]\n",
    "    df_tl_diff = df_tl_diff.query('diff_TL <= 0')\n",
    "    subjects_to_drop_dict[f\"{hemi}_{protocol}\"] = list(df_tl_diff[\"subject_ID\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which brain label power is significantly different (pre vs post) at which frequency range and protocol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## which brain label power is significantly different (pre vs post) at which frequency range and protocol?\n",
    "hemis = [\"left\", \"right\"]\n",
    "prots = [\"0.1 Hz\", \"1 Hz\", \"10 Hz\", \"20 Hz\"][1:]\n",
    "franges = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "brain_labels = read_labels_from_annot(subject=\"fsaverage\", parc=\"aparc\", verbose=False)[:-1]\n",
    "bls = [bl.name for bl in brain_labels]\n",
    "bls.append(\"whole-lh\")\n",
    "bls.append(\"whole-rh\")\n",
    "combs = product(hemis, prots, franges)\n",
    "p_thr = 0.05\n",
    "t_test = True\n",
    "k_sample_test = False\n",
    "texts = []\n",
    "sig_brain_regions = {}\n",
    "for hemi, prot, frange in combs:\n",
    "    sig_brain_regions[f\"{hemi}_{prot}_{frange}\"] = []\n",
    "\n",
    "combs = product(hemis, prots, franges)\n",
    "for hemi, prot, frange in combs:\n",
    "    subjects_to_drop = subjects_to_drop_dict[f\"{hemi}_{prot}\"]\n",
    "    df_1 = df\n",
    "    # df_1 = df[~df['subject_ID'].isin(subjects_to_drop)]\n",
    "    p_vals = []\n",
    "    for bl in bls:\n",
    "        df_sub = df_1.query(f'hemisphere == \"{hemi}\" & protocol == \"{prot}\" & frequency_band == \"{frange}\" & brain_label == \"{bl}\"')\n",
    "        group_pre = df_sub[df_sub[\"run\"]==\"pre\"][\"power\"].to_numpy()\n",
    "        group_post = df_sub[df_sub[\"run\"]==\"post\"][\"power\"].to_numpy()\n",
    "\n",
    "        if t_test:\n",
    "            t_stat, p_value = ttest_rel(group_pre, group_post)\n",
    "        if k_sample_test:\n",
    "            stat, p_value = KSample(\"Dcorr\").test(group_pre, group_post)\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            print(f\"{hemi}_{prot}_{frange}_{bl}: uncorrected : {round(p_value, 4)}\")\n",
    "            sig_brain_regions[f\"{hemi}_{prot}_{frange}\"].append(bl)\n",
    "\n",
    "        p_vals.append(p_value)\n",
    "    \n",
    "    adjusted_p_vals = multipletests(np.array(p_vals), alpha=0.05, method='fdr_bh')[1]\n",
    "    p_idxs = np.where(adjusted_p_vals < p_thr)[0]\n",
    "    if len(p_idxs) > 0:\n",
    "        print(f\"{hemi}_{prot}_{frange}_{bl}: {round(p_value, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the dictionary\n",
    "with open(Path.cwd().parent / \"data\" / \"dataframes\" / \"results_new\" / \"whole_bl.pkl\", 'wb') as pickle_file:\n",
    "    pickle.dump(sig_brain_regions, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. contrasts between stimulation protocols (pre-to-post changes; âˆ†rsEEG at each protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = [\"0.1 Hz\", \"1 Hz\", \"10 Hz\", \"20 Hz\"]\n",
    "franges = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "hemis = [\"left\", \"right\"]\n",
    "brain_labels = read_labels_from_annot(subject=\"fsaverage\", parc=\"aparc\", verbose=False)[:-1]\n",
    "bls = [bl.name for bl in brain_labels]\n",
    "bls.append(\"whole-lh\")\n",
    "bls.append(\"whole-rh\")\n",
    "combs = product(hemis, hemis, protocols[1:], protocols, franges)\n",
    "p_thr = 0.05\n",
    "t_test = True\n",
    "k_sample_test = False\n",
    "\n",
    "sig_brain_regions = {}\n",
    "for hemi_1, hemi_2, prot_1, prot_2, frange in combs:\n",
    "    p_vals = []\n",
    "    if hemi_1 == hemi_2 and prot_2 == \"0.1 Hz\":\n",
    "        sig_brain_regions[f\"{hemi_1}_{prot_1}_{frange}\"] = []\n",
    "\n",
    "\n",
    "combs = product(hemis, hemis, protocols[1:], protocols, franges)\n",
    "for hemi_1, hemi_2, prot_1, prot_2, frange in combs:\n",
    "    p_vals = []\n",
    "    if hemi_1 == hemi_2 and prot_2 == \"0.1 Hz\":\n",
    "        subjects_to_drop = subjects_to_drop_dict[f\"{hemi_1}_{prot_1}\"]\n",
    "        # df_1 = df[~df['subject_ID'].isin(subjects_to_drop)]\n",
    "        df_1 = df\n",
    "        for bl in bls:\n",
    "            df_sub = df_1.query(f'hemisphere == \"{hemi_1}\" & protocol == \"{prot_1}\" & frequency_band == \"{frange}\" & brain_label == \"{bl}\"')\n",
    "            df_pivot = df_sub.pivot(index='subject_ID', columns='run', values='power')\n",
    "            df_pivot['power_difference'] = df_pivot['post'] - df_pivot['pre']\n",
    "            power_diff_prot_1 = df_pivot['power_difference'].values\n",
    "\n",
    "            df_sub = df_1.query(f'hemisphere == \"{hemi_2}\" & protocol == \"{prot_2}\" & frequency_band == \"{frange}\" & brain_label == \"{bl}\"')\n",
    "            df_pivot = df_sub.pivot(index='subject_ID', columns='run', values='power')\n",
    "            df_pivot['power_difference'] = df_pivot['post'] - df_pivot['pre']\n",
    "            power_diff_prot_2 = df_pivot['power_difference'].values\n",
    "\n",
    "            if t_test:\n",
    "                t_stat, p_value = ttest_rel(power_diff_prot_1, power_diff_prot_2)\n",
    "            if k_sample_test:\n",
    "                stat, p_value = KSample(\"Dcorr\").test(power_diff_prot_1, power_diff_prot_2)\n",
    "            \n",
    "            if p_value < p_thr:\n",
    "                print(f\"{hemi_1}_{prot_1}_{prot_2}_{frange}_{bl}: uncorrected: {round(p_value, 4)}\")\n",
    "                sig_brain_regions[f\"{hemi_1}_{prot_1}_{frange}\"].append(bl)\n",
    "            p_vals.append(p_value)\n",
    "\n",
    "        adjusted_p_vals = multipletests(np.array(p_vals), alpha=0.05, method='fdr_bh')[1]\n",
    "        p_idxs = np.where(adjusted_p_vals < p_thr)[0]\n",
    "        if len(p_idxs) > 0:\n",
    "            print(f\"{prot_1}_{hemi_1} vs {prot_2}_{hemi_2} at {frange}\")\n",
    "            for idx in p_idxs:\n",
    "                print(np.array(bls)[idx], round(adjusted_p_vals[idx],4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the dictionary\n",
    "with open(Path.cwd().parent / \"data\" / \"dataframes\" / \"results_new\" / \"whole_compared_to_sham_bl_.pkl\", 'wb') as pickle_file:\n",
    "    pickle.dump(sig_brain_regions, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bls that are significant pre to post and significant than sham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the dictionaries\n",
    "folder_name = Path.cwd().parent / \"data\" / \"dataframes\" / \"results_new\"\n",
    "\n",
    "with open(folder_name / \"whole_bl.pkl\", 'rb') as pickle_file:\n",
    "    dict_1 = pickle.load(pickle_file)\n",
    "with open(folder_name / \"whole_compared_to_sham_bl.pkl\", 'rb') as pickle_file:\n",
    "    dict_2 = pickle.load(pickle_file)\n",
    "\n",
    "## loop over brain labels to find commons\n",
    "for key in dict_1:\n",
    "    vals_1 = dict_1[key]\n",
    "    vals_2 = dict_2[key]\n",
    "    common_elements = set(vals_1) & set(vals_2)\n",
    "    if len(common_elements):\n",
    "        print(f\"{key}: {list(common_elements)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dict_2.items():\n",
    "    if len(value):\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. contrasts between stimulation protocols (pre-to-post changes; âˆ†rsEEG = pre/post vs left/right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = [\"0.1Hz\", \"1Hz\", \"10Hz\", \"20Hz\"]\n",
    "franges = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "p_thr = 0.05\n",
    "subjects_to_drop = [\"3dx2e\", \"6sjul\", \"musky\", \"8kmc7\", \"cmh15\", \"uvxfg\", \"2fjeu\", \"dws0m\", \"gigcm\", \"6wms4\"]\n",
    "df_1 = df[~df['subject_ID'].isin(subjects_to_drop)]\n",
    "\n",
    "for protocol, frange in product(protocols, franges):\n",
    "    df1 = df_1.query(f'protocol == \"{protocol}\" & frequency_band == \"{frange}\"')\n",
    "    pivoted_df = df1.pivot(index=\"subject_ID\", columns=[\"hemisphere\", \"run\", \"brain_label\"], values='power')\n",
    "    pivoted_df = pivoted_df.dropna()\n",
    "    df_array = pivoted_df.to_numpy()\n",
    "\n",
    "    data = df_array.reshape(len(df_array), 4, int(df_array.shape[-1]/4)) # left/right * post/pre\n",
    "    fvals, pvals = f_mway_rm(data, factor_levels=[2, 2], effects=\"A*B\")\n",
    "    if pvals[-1].min() < p_thr:\n",
    "        p_vals = pvals[-1]\n",
    "        reject, p_adj = fdr_correction(p_vals)\n",
    "        idx = np.where(reject == True)[0]\n",
    "        bl = np.array(bls)[idx]\n",
    "        print(f\"{protocol}_{frange}_{bl}_{p_adj[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## connectivity analysis (pre vs post)\n",
    "method = \"coh\"\n",
    "stat_method = \"fdr_bh\"\n",
    "\n",
    "protocols = [\"_0.1Hz\", \"_1Hz\", \"_10Hz\", \"_20Hz\"][1:]\n",
    "franges = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "\n",
    "for protocol, hemisphere, freq in product(protocols, [\"_L_\", \"_R_\"], franges):\n",
    "    if hemisphere == \"_L_\": hemi = \"left\"\n",
    "    if hemisphere == \"_R_\": hemi = \"right\"\n",
    "    \n",
    "    subjects_to_drop = subjects_to_drop_dict[f\"{hemi}_{protocol[1:-2]} Hz\"]\n",
    "    n_labels = 68\n",
    "    low_tri_idxs = np.tril_indices(n_labels, k=-1) \n",
    "    group_pre = []\n",
    "    group_post = []\n",
    "    fnames = []\n",
    "    folder_name = Path.cwd().parent / \"data\" / \"dataframes\" / \"conns\"\n",
    "    for file in sorted(os.listdir(folder_name)):\n",
    "        if file.endswith(\".pkl\"):\n",
    "            if file[:5] not in subjects_to_drop: \n",
    "                if protocol in file and hemisphere in file:\n",
    "                    fname = folder_name / file\n",
    "                    \n",
    "                    if \"_pre\" in file: \n",
    "                        with open(fname, \"rb\") as filename:\n",
    "                            my_dict = pickle.load(filename)\n",
    "                        if method == \"wpli\": group_pre.append(my_dict[freq][0])\n",
    "                        if method == \"coh\": group_pre.append(my_dict[freq][1])\n",
    "\n",
    "                    if \"_post\" in file: \n",
    "                        with open(fname, \"rb\") as filename:\n",
    "                            my_dict = pickle.load(filename)\n",
    "                        if method == \"wpli\": group_post.append(my_dict[freq][0])\n",
    "                        if method == \"coh\": group_post.append(my_dict[freq][1])\n",
    "\n",
    "    vectors_pre = np.array([con[low_tri_idxs] for con in group_pre])\n",
    "    vectors_post = np.array([con[low_tri_idxs] for con in group_post])\n",
    "\n",
    "    for vector in vectors_pre:\n",
    "        zero_edges = np.where(vector < vector.max() * 0.01)[0]\n",
    "        vector[zero_edges] = 0\n",
    "    for vector in vectors_post:\n",
    "        zero_edges = np.where(vector < vector.max() * 0.01)[0]\n",
    "        vector[zero_edges] = 0\n",
    "\n",
    "    stat, p_values = ttest_rel(vectors_pre, vectors_post)\n",
    "    reject_null, p_corrected, _, _ = multipletests(pvals=p_values, alpha=0.05, method=stat_method)\n",
    "    if p_corrected.min() < 0.05:\n",
    "        print(p_corrected.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_method = \"fdr_bh\"\n",
    "protocols = [\"_0.1Hz\", \"_1Hz\", \"_10Hz\", \"_20Hz\"][1:]\n",
    "franges = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "n_labels = 68\n",
    "low_tri_idxs = np.tril_indices(n_labels, k=-1) \n",
    "\n",
    "for protocol, hemisphere, freq in product(protocols, [\"_L_\", \"_R_\"], franges):\n",
    "    if hemisphere == \"_L_\": hemi = \"left\"\n",
    "    if hemisphere == \"_R_\": hemi = \"right\"\n",
    "\n",
    "    subjects_to_drop = subjects_to_drop_dict[f\"{hemi}_{protocol[1:-2]} Hz\"]\n",
    "    group_pre = []\n",
    "    group_post = []\n",
    "    folder_name = Path.cwd().parent / \"data\" / \"dataframes\" / \"graphs\"\n",
    "    for file in sorted(os.listdir(folder_name)):\n",
    "        if file.endswith(\".pkl\"):\n",
    "            if file[:5] not in subjects_to_drop: \n",
    "                if protocol in file and hemisphere in file:\n",
    "                    fname = folder_name / file\n",
    "                    if \"_pre\" in file: \n",
    "                        with open(fname, \"rb\") as filename:\n",
    "                            my_dict = pickle.load(filename)\n",
    "                        graph = my_dict[freq]\n",
    "                        group_pre.append(graph / np.linalg.norm(graph, 'fro'))\n",
    "                    \n",
    "                    if \"_post\" in file: \n",
    "                        with open(fname, \"rb\") as filename:\n",
    "                            my_dict = pickle.load(filename)\n",
    "                        graph = my_dict[freq]\n",
    "                        group_post.append(graph / np.linalg.norm(graph, 'fro'))\n",
    "\n",
    "    vectors_pre = np.array([con[low_tri_idxs] for con in group_pre])\n",
    "    vectors_post = np.array([con[low_tri_idxs] for con in group_post])\n",
    "\n",
    "    # removing very small connections\n",
    "    for vector in vectors_pre:\n",
    "        zero_edges = np.where(vector < vector.max() * 0.01)[0]\n",
    "        vector[zero_edges] = 0\n",
    "    for vector in vectors_post:\n",
    "        zero_edges = np.where(vector < vector.max() * 0.01)[0]\n",
    "        vector[zero_edges] = 0\n",
    "\n",
    "    stat, p_values = ttest_rel(vectors_pre, vectors_post)\n",
    "    reject_null, p_corrected, _, _ = multipletests(pvals=p_values, alpha=0.05, method=stat_method)\n",
    "    if p_corrected.min() < 0.05:\n",
    "        print(p_corrected.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responders vs non-responders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df[\"subject_ID\"] != \"6wms4\"]\n",
    "# non_responders = [\"3dx2e\", \"6sjul\", \"musky\", \"8kmc7\", \"cmh15\", \"uvxfg\", \"2fjeu\", \"dws0m\", \"gigcm\", \"6wms4\"]\n",
    "# df[\"type\"] = df[\"subject_ID\"].apply(lambda x: \"responder\" if x not in non_responders else \"non-responder\")\n",
    "\n",
    "hemis = [\"left\", \"right\"]\n",
    "prots = [\"0.1 Hz\", \"1 Hz\", \"10 Hz\", \"20 Hz\"][1:2]\n",
    "franges = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"][-1:]\n",
    "brain_labels = read_labels_from_annot(subject=\"fsaverage\", parc=\"aparc\", verbose=False)[:-1]\n",
    "bls = [bl.name for bl in brain_labels]\n",
    "bls.append(\"whole-lh\")\n",
    "bls.append(\"whole-rh\")\n",
    "combs = product(hemis, prots, franges)\n",
    "p_thr = 0.05\n",
    "stat_method = \"fdr_bh\"\n",
    "\n",
    "for hemi, prot, frange in combs:\n",
    "    non_responders = subjects_to_drop_dict[prot]\n",
    "    df[\"type\"] = df[\"subject_ID\"].apply(lambda x: \"responder\" if x not in non_responders else \"non-responder\")\n",
    "    p_vals = []\n",
    "    for bl in bls[-1:]:\n",
    "        df_sub = df.query(f'hemisphere == \"{hemi}\" & protocol == \"{prot}\" & frequency_band == \"{frange}\" & brain_label == \"{bl}\"')\n",
    "        df_pivot = df_sub.pivot(index='subject_ID', columns='run', values='power')\n",
    "        df_pivot['power_difference'] = df_pivot['post'] - df_pivot['pre']\n",
    "        df_pivot_1 = df_pivot.query('subject_ID not in @non_responders')\n",
    "        df_pivot_2 = df_pivot.query('subject_ID in @non_responders')\n",
    "        power_diff_prot_1 = df_pivot_1['power_difference'].values\n",
    "        power_diff_prot_2 = df_pivot_2['power_difference'].values\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(9, 4))\n",
    "        ax.violinplot([power_diff_prot_1, power_diff_prot_2], showmeans=False, showmedians=True)\n",
    "        ax.set_title(f\"{prot}, {hemi}, {frange}_{bl}\")\n",
    "\n",
    "        t_stat, p_value = ttest_ind(power_diff_prot_1, power_diff_prot_2)\n",
    "        p_vals.append(p_value)\n",
    "\n",
    "    reject_null, p_corrected, _, _ = multipletests(pvals=p_vals, alpha=0.05, method=stat_method)\n",
    "    \n",
    "    if p_corrected.min() < 0.05:\n",
    "        for idx in np.where(p_corrected < 0.05)[0]:\n",
    "            print(f\"{prot}, {hemi}, {frange}_{bls[idx]}_{p_corrected.min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check behavioural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define responders and non responders\n",
    "fname = \"/Users/payamsadeghishabestari/codes/regTMS/data/behavioral_data/TL_data.xlsx\"\n",
    "df_tl = pd.read_excel(fname)\n",
    "df_tl[\"protcol\"].replace(\"1Hz\", \"1 Hz\", inplace=True)\n",
    "df_tl.rename(columns={'ID': 'subject_ID'}, inplace=True)\n",
    "df_tl.rename(columns={'protcol': 'protocol'}, inplace=True)\n",
    "df_tl.drop(columns=\"NO.\", inplace=True)\n",
    "df_tl['pre_avg'] = df_tl.filter(like='pre').mean(axis=1)\n",
    "df_tl['post_avg'] = df_tl.filter(like='post').mean(axis=1)\n",
    "df_tl = df_tl.melt(id_vars=[\"subject_ID\", \"hemisphere\", \"protocol\"], \n",
    "                    value_vars=['pre_avg', 'post_avg'], \n",
    "                    var_name='run', \n",
    "                    value_name='tl_avg')\n",
    "df_tl['run'] = df_tl['run'].str.replace('_avg', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = [\"left\", \"right\"]\n",
    "order = [\"0.1 Hz\", \"1 Hz\", \"10 Hz\", \"20 Hz\"]\n",
    "hue_order = [\"pre\", \"post\"]\n",
    "cl1 = sns.cubehelix_palette(10, rot=2.5, light=.7, reverse=True)[7]\n",
    "cl2 = sns.cubehelix_palette(10, rot=-2*np.pi/10, light=.7, reverse=True)[3]\n",
    "g = sns.FacetGrid(data=df_tl, col=\"hemisphere\", col_order=col_order, height=4, aspect=2)\n",
    "g.map_dataframe(sns.boxplot, x=\"protocol\", y=\"tl_avg\", hue=\"run\", order=order, hue_order=hue_order,\n",
    "                fill=False, gap=0.2, palette=[cl1, cl2], linewidth=2)\n",
    "g.map_dataframe(sns.stripplot, x=\"protocol\", y=\"tl_avg\", hue=\"run\", order=order, hue_order=hue_order,\n",
    "                dodge=True, palette=[cl1, cl2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = df_tl['protocol'].unique()\n",
    "p_values = []\n",
    "for protocol in protocols:\n",
    "    subset = df_tl[df_tl['protocol'] == protocol]\n",
    "    data_pre = subset[subset['run'] == \"pre\"]\n",
    "    data_post = subset[subset['run'] == \"post\"]\n",
    "    t_stat, p_value = ttest_rel(data_pre[\"tl_avg\"], data_post[\"tl_avg\"], alternative='greater')\n",
    "    print(f'Stimulus: {protocol}, t-statistic: {t_stat}, p-value: {p_value}')\n",
    "    p_values.append(p_value)\n",
    "\n",
    "corrected_p_values = multipletests(p_values, method='bonferroni')\n",
    "print('Bonferroni corrected p-values:', corrected_p_values[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
