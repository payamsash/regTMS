{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/payamsadeghishabestari/virtual_envs/.venv/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "import os\n",
    "import os.path as op\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "from mne.datasets import fetch_fsaverage\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne_icalabel import label_components\n",
    "from tqdm.contrib.itertools import product\n",
    "from mne.stats import permutation_t_test\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse_epochs\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "from learn_graph import log_degree_barrier\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize parameters\n",
    "sfreq = 250.0\n",
    "(l_freq, h_freq, no_freq) = (0.1, 100.0, 50.0)\n",
    "montage = mne.channels.make_standard_montage(\"easycap-M1\")\n",
    "verbose = False\n",
    "fs_dir = fetch_fsaverage(verbose=verbose)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "bem = op.join(fs_dir, \"bem\", \"fsaverage-5120-5120-5120-bem-sol.fif\")\n",
    "bands_dict = {\"delta\": [0.5, 4], \"theta\": [4, 8], \"alpha\": [8, 13],\n",
    "            \"beta\": [13, 30], \"gamma\": [30, 80]}\n",
    "\n",
    "snr = 1.0  \n",
    "lambda2 = 1.0 / snr**2\n",
    "brain_labels = mne.read_labels_from_annot(subject=\"fsaverage\", parc=\"aparc\", verbose=verbose)[:-1]\n",
    "bl_names = [bl.name for bl in brain_labels]\n",
    "power_keys = [\"subject_ID\", \"hemisphere\", \"protocol\", \"run\", \"frequency_band\", \"brain_label\", \"power\"]\n",
    "\n",
    "## initialize parameters\n",
    "compute_power = True\n",
    "compute_conn = True\n",
    "compute_graph = True\n",
    "create_report = True\n",
    "\n",
    "## loop over subjects\n",
    "folder_name = Path.cwd().parent / \"data\" / \"EEG_data\"\n",
    "for file in tqdm(sorted(os.listdir(folder_name))[300:]):\n",
    "    if file.endswith(\".set\"):\n",
    "        fname = folder_name / file\n",
    "        subject_id = file[:5]\n",
    "        if file[8:9] == \"R\": hemisphere = \"right\"\n",
    "        if file[8:9] == \"L\": hemisphere = \"left\"\n",
    "        if file[-7:-4] == \"pre\": run = \"pre\"\n",
    "        if file[-8:-4] == \"post\": run = \"post\"\n",
    "        if \"_0.1Hz\" in file: protocol = \"0.1Hz\"\n",
    "        if \"_1Hz\" in file: protocol = \"1Hz\"\n",
    "        if \"_10Hz\" in file: protocol = \"10Hz\"\n",
    "        if \"_20Hz\" in file: protocol = \"20Hz\"\n",
    "\n",
    "        my_dict = {}\n",
    "        power_dict = {key: [] for key in power_keys}\n",
    "        con_dict = {}\n",
    "        graphs_dict = {}\n",
    "\n",
    "        ## read raw eeg files\n",
    "        raw = mne.io.read_raw_eeglab(input_fname=fname, preload=True, verbose=verbose)\n",
    "        raw.annotations.delete(range(len(raw.annotations)))\n",
    "\n",
    "        ## set montage (FPz -> Fpz)\n",
    "        raw.set_montage(montage=montage, match_case=False, on_missing=\"raise\")\n",
    "\n",
    "        ## resample and filter, re-referencing\n",
    "        raw.resample(sfreq=sfreq, verbose=verbose)\n",
    "        raw.filter(l_freq=l_freq, h_freq=h_freq, verbose=verbose)\n",
    "        raw.notch_filter(freqs=no_freq, verbose=verbose) \n",
    "        raw.set_eeg_reference(\"average\", projection=False, verbose=verbose)\n",
    "\n",
    "        ## ICA\n",
    "        ica = mne.preprocessing.ICA(n_components=0.95, max_iter=800, method='infomax',\n",
    "                                    fit_params=dict(extended=True))\n",
    "        try:\n",
    "            ica.fit(raw, verbose=verbose)\n",
    "        except:\n",
    "            ica = mne.preprocessing.ICA(n_components=5, max_iter=800, method='infomax',\n",
    "                                    fit_params=dict(extended=True))\n",
    "            ica.fit(raw, verbose=verbose)\n",
    "        \n",
    "        ic_dict = label_components(raw, ica, method=\"iclabel\")\n",
    "        ic_labels = ic_dict[\"labels\"]\n",
    "        ic_probs = ic_dict[\"y_pred_proba\"]\n",
    "        eog_indices = []\n",
    "        for idx, label in enumerate(ic_labels):\n",
    "            if label == \"eye blink\" and ic_probs[idx] > 0.70:\n",
    "                eog_indices.append(idx)\n",
    "\n",
    "        if len(eog_indices) > 0:\n",
    "            eog_components = ica.plot_properties(raw, picks=eog_indices, verbose=verbose, show=False)\n",
    "            for fig_idx, fig in enumerate(eog_components):\n",
    "                pred_value = int(ic_probs[eog_indices[fig_idx]] * 1e2)\n",
    "                fig.axes[0].set_title(f\"pred score: 0.{pred_value}\")\n",
    "        \n",
    "        ica.apply(raw, exclude=eog_indices, verbose=verbose)\n",
    "        \n",
    "        ## sensor analysis\n",
    "        epochs = mne.make_fixed_length_epochs(raw, duration=5, verbose=verbose)\n",
    "        for frange, freqs in bands_dict.items():\n",
    "            psd_vals = epochs.compute_psd(fmin=freqs[0], fmax=freqs[1],\n",
    "                                        verbose=verbose).get_data().mean(axis=2)\n",
    "            \n",
    "            my_dict[f\"{frange}\"] = psd_vals\n",
    "        \n",
    "        fname_save = Path.cwd().parent / \"data\" / \"dataframes\" / \"visit_2\" / \"sensor\" / f\"{subject_id}_{protocol}_{hemisphere}_{run}.pkl\"\n",
    "        with open(fname_save, \"wb\") as file_pkl:\n",
    "            pickle.dump(my_dict, file_pkl)\n",
    "\n",
    "        ## source power\n",
    "        info = raw.info\n",
    "        fwd = mne.make_forward_solution(info, trans=\"fsaverage\", src=src_fname, bem=bem, eeg=True,\n",
    "                                        meg=False, verbose=verbose)\n",
    "        noise_cov = mne.make_ad_hoc_cov(info, std=None, verbose=verbose)\n",
    "        inverse_operator = make_inverse_operator(info, fwd, noise_cov, verbose=verbose)\n",
    "        src = inverse_operator[\"src\"]\n",
    "        raw.set_eeg_reference(\"average\", projection=True, verbose=verbose)\n",
    "        \n",
    "        for band, (freq_l, freq_h) in bands_dict.items(): \n",
    "            print(f\"working on {file} at frequency range {band}.\")\n",
    "            raw_filt = raw.copy().filter(freq_l, freq_h, verbose=verbose)\n",
    "            epochs = mne.make_fixed_length_epochs(raw_filt, duration=5.0, preload=True, verbose=verbose)\n",
    "            \n",
    "            ## compute power in labels (try to not fill memory)\n",
    "            if compute_power:\n",
    "                stcs = apply_inverse_epochs(epochs, inverse_operator, lambda2, method=\"dSPM\",\n",
    "                                            label=None, return_generator=True, verbose=verbose)\n",
    "                label_ts = mne.extract_label_time_course(stcs, brain_labels, src, mode=\"mean\",\n",
    "                                                        return_generator=False, verbose=verbose)\n",
    "                powers = np.array(label_ts).mean(axis=(0, 2))\n",
    "                del stcs, label_ts\n",
    "                \n",
    "                ## fill in the dataframe\n",
    "                for label, power in zip(brain_labels, powers):\n",
    "                    power_dict[\"subject_ID\"].append(subject_id)\n",
    "                    power_dict[\"hemisphere\"].append(hemisphere)\n",
    "                    power_dict[\"protocol\"].append(protocol)\n",
    "                    power_dict[\"run\"].append(run)\n",
    "                    power_dict[\"frequency_band\"].append(band)\n",
    "                    power_dict[\"brain_label\"].append(label.name)\n",
    "                    power_dict[\"power\"].append(power)\n",
    "\n",
    "            ## compute connectivity between labels (wPLI, Coh)\n",
    "            if compute_conn:\n",
    "                stcs = apply_inverse_epochs(epochs, inverse_operator, lambda2, method=\"dSPM\",\n",
    "                                            label=None, return_generator=True, verbose=verbose)\n",
    "                label_ts = mne.extract_label_time_course(stcs, brain_labels, src, mode=\"mean\",\n",
    "                                                        return_generator=False, verbose=verbose)\n",
    "                conns = spectral_connectivity_epochs(data=label_ts, names=bl_names,\n",
    "                                                    method=[\"wpli\", \"coh\"], sfreq=sfreq,\n",
    "                                                    fmin=freq_l, fmax=freq_h, faverage=True,\n",
    "                                                    verbose=verbose)\n",
    "                del stcs\n",
    "                con_data = np.array([con.get_data(output=\"dense\")[:, :, 0] for con in conns])\n",
    "                con_dict[band] = con_data\n",
    "\n",
    "            ## learn graph on FC data\n",
    "            if compute_graph:\n",
    "                label_ts_reshaped = np.array(label_ts).transpose(1, 0, 2)\n",
    "                X = label_ts_reshaped.reshape(label_ts_reshaped.shape[0], -1)\n",
    "                graph = log_degree_barrier(X=X, dist_type='sqeuclidean', alpha=1,\n",
    "                                                beta=1, step=0.5, w0=None, maxit=10000, rtol=1e-16,\n",
    "                                                retall=False, verbosity='NONE')\n",
    "                graphs_dict[band] = graph\n",
    "\n",
    "        ## fill and save the report\n",
    "        if compute_power: \n",
    "            fname_save = Path.cwd().parent / \"data\" / \"dataframes\" / \"visit_2\" / \"powers\" / f\"{file[:-4]}.csv\"\n",
    "            df_power = pd.DataFrame(power_dict)\n",
    "            df_power.to_csv(fname_save)\n",
    "\n",
    "        if compute_conn: \n",
    "            fname_save = Path.cwd().parent / \"data\" / \"dataframes\" / \"visit_2\" / \"conns\" / f\"{file[:-4]}.pkl\"\n",
    "            with open(fname_save, \"wb\") as file_pkl:\n",
    "                pickle.dump(con_dict, file_pkl)\n",
    "\n",
    "        if compute_graph:\n",
    "            fname_save = Path.cwd().parent / \"data\" / \"dataframes\" / \"visit_2\" / \"graphs\" / f\"{file[:-4]}.pkl\"\n",
    "            with open(fname_save, \"wb\") as file_pkl:\n",
    "                pickle.dump(graphs_dict, file_pkl)\n",
    "        \n",
    "        if create_report:\n",
    "            report = mne.Report(title=f\"report_subject_{subject_id}\", verbose=verbose)\n",
    "            report.add_raw(raw=raw, title=\"recording info\", butterfly=False, psd=False) \n",
    "            if len(eog_indices) > 0:\n",
    "                report.add_figure(fig=eog_components, title=\"EOG components\", image_format=\"PNG\")\n",
    "            fname_report = Path.cwd().parent / \"data\" / \"dataframes\" / \"visit_2\" / \"reports\" / f\"{file[:-4]}.html\"\n",
    "            report.save(fname=fname_report, open_browser=False, overwrite=True, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the difference in sensor space (epoch wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_eeglab(input_fname=\"/Users/payamsadeghishabestari/codes/regTMS/data/EEG_data/2bbyx_2_L_0.1Hz_post.set\",\n",
    "                            preload=True, verbose=False)\n",
    "montage = mne.channels.make_standard_montage(\"easycap-M1\")\n",
    "raw.annotations.delete(range(len(raw.annotations)))\n",
    "raw.set_montage(montage=montage, match_case=False, on_missing=\"raise\")\n",
    "info = raw.info\n",
    "\n",
    "folder_name = Path.cwd().parent / \"data\" / \"dataframes\" / \"visit_2\" / \"sensor\"\n",
    "subject_ids = []\n",
    "for file in sorted(os.listdir(folder_name)):\n",
    "    if file.endswith(\".pkl\"):\n",
    "        subject_ids.append(file[:5])\n",
    "subject_ids = list(np.unique(np.array(subject_ids)))    \n",
    "subjects_to_drop = [\"3dx2e\", \"6sjul\", \"musky\", \"8kmc7\", \"cmh15\", \"uvxfg\", \"2fjeu\", \"dws0m\", \"gigcm\"]\n",
    "\n",
    "protocols = [\"0.1Hz\", \"1Hz\", \"10Hz\", \"20Hz\"][:1]\n",
    "hemis = [\"left\", \"right\"]\n",
    "franges = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "combs = product(protocols, hemis, franges)\n",
    "\n",
    "for protocol, hemi, frange in combs:\n",
    "    x1, x2 = [], []\n",
    "    for subject_id in subject_ids:\n",
    "        if subject_id not in subjects_to_drop:\n",
    "            fname_pre = folder_name / f\"{subject_id}_{protocol}_{hemi}_pre.pkl\"\n",
    "            fname_post = folder_name / f\"{subject_id}_{protocol}_{hemi}_post.pkl\"\n",
    "\n",
    "            with open(fname_pre, \"rb\") as fpre:\n",
    "                dict_pre = pickle.load(fpre)\n",
    "            with open(fname_post, \"rb\") as fpost:\n",
    "                dict_post = pickle.load(fpost)\n",
    "\n",
    "            x1.append(dict_pre[frange])\n",
    "            x2.append(dict_post[frange])\n",
    "\n",
    "    x1 = np.concatenate(x1, axis=0)\n",
    "    x2 = np.concatenate(x2, axis=0)\n",
    "    n_epochs = min(len(x1), len(x2))\n",
    "\n",
    "    X = x2[:n_epochs] - x1[:n_epochs]\n",
    "    T0, p_values, H0 = permutation_t_test(X=X, n_permutations=10000)\n",
    "    \n",
    "    evoked = mne.EvokedArray(-np.log10(p_values)[:, np.newaxis], info, tmin=0.0)\n",
    "    mask = p_values[:, np.newaxis] <= 0.05\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    evoked.plot_topomap(\n",
    "        ch_type=\"eeg\",\n",
    "        times=[0],\n",
    "        scalings=1,\n",
    "        colorbar=False,\n",
    "        time_format=None,\n",
    "        cmap=None,\n",
    "        vlim=(0, np.max),\n",
    "        units=\"log10(p)\",\n",
    "        cbar_fmt=\"%0.1f\",\n",
    "        mask=mask,\n",
    "        size=3,\n",
    "        show_names=False,\n",
    "        time_unit=\"s\",\n",
    "        axes=ax\n",
    "    )\n",
    "    ax.set_title(f\"{protocol}_{hemi}_{frange}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the difference in sensor space (subject wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6c91e9f03d45cdb7f04f75581bd139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['pre_avg'] = df_tl.filter(like='pre').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['post_avg'] = df_tl.filter(like='post').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub[\"diff_TL\"] = df_tl_sub['pre_avg'] - df_tl_sub['post_avg']\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['pre_avg'] = df_tl.filter(like='pre').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['post_avg'] = df_tl.filter(like='post').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub[\"diff_TL\"] = df_tl_sub['pre_avg'] - df_tl_sub['post_avg']\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['pre_avg'] = df_tl.filter(like='pre').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['post_avg'] = df_tl.filter(like='post').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub[\"diff_TL\"] = df_tl_sub['pre_avg'] - df_tl_sub['post_avg']\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['pre_avg'] = df_tl.filter(like='pre').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['post_avg'] = df_tl.filter(like='post').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub[\"diff_TL\"] = df_tl_sub['pre_avg'] - df_tl_sub['post_avg']\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['pre_avg'] = df_tl.filter(like='pre').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['post_avg'] = df_tl.filter(like='post').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub[\"diff_TL\"] = df_tl_sub['pre_avg'] - df_tl_sub['post_avg']\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['pre_avg'] = df_tl.filter(like='pre').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub['post_avg'] = df_tl.filter(like='post').mean(axis=1)\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/3124130704.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tl_sub[\"diff_TL\"] = df_tl_sub['pre_avg'] - df_tl_sub['post_avg']\n"
     ]
    }
   ],
   "source": [
    "## define responders and non responders\n",
    "subjects_to_drop_dict = {}\n",
    "prots = [\"1 Hz\", \"10 Hz\", \"20 Hz\"]\n",
    "hemis = [\"left\", \"right\"]\n",
    "all_combs = product(prots, hemis)\n",
    "for protocol, hemi in all_combs:\n",
    "    fname = \"/Users/payamsadeghishabestari/codes/regTMS/data/behavioral_data/TL_data.xlsx\"\n",
    "    df_tl = pd.read_excel(fname)\n",
    "    df_tl[\"protcol\"] = df_tl[\"protcol\"].replace(\"1Hz\", \"1 Hz\")\n",
    "    df_tl_sub = df_tl.query(f'protcol == \"{protocol}\" & hemisphere == \"{hemi}\"')\n",
    "    df_tl_sub['pre_avg'] = df_tl.filter(like='pre').mean(axis=1)\n",
    "    df_tl_sub['post_avg'] = df_tl.filter(like='post').mean(axis=1)\n",
    "    df_tl_sub[\"diff_TL\"] = df_tl_sub['pre_avg'] - df_tl_sub['post_avg']\n",
    "    df_tl_sub = df_tl_sub.rename(columns={'ID': 'subject_ID'})\n",
    "    df_tl_diff = df_tl_sub[[\"subject_ID\", \"diff_TL\"]]\n",
    "    df_tl_diff = df_tl_diff.query('diff_TL <= 0')\n",
    "    subjects_to_drop_dict[f\"{hemi}_{protocol}\"] = list(df_tl_diff[\"subject_ID\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/1030094895.py:1: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(input_fname=\"/Users/payamsadeghishabestari/codes/regTMS/data/EEG_data/2bbyx_2_L_0.1Hz_post.set\",\n",
      "/var/folders/20/hsy69tx529ndn3rkv5gzcf0c0000gn/T/ipykernel_1542/1030094895.py:1: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(input_fname=\"/Users/payamsadeghishabestari/codes/regTMS/data/EEG_data/2bbyx_2_L_0.1Hz_post.set\",\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6e0b798ea440ccbb6b391731ca4c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw = mne.io.read_raw_eeglab(input_fname=\"/Users/payamsadeghishabestari/codes/regTMS/data/EEG_data/2bbyx_2_L_0.1Hz_post.set\",\n",
    "                            preload=True, verbose=False)\n",
    "montage = mne.channels.make_standard_montage(\"easycap-M1\")\n",
    "raw.annotations.delete(range(len(raw.annotations)))\n",
    "raw.set_montage(montage=montage, match_case=False, on_missing=\"raise\")\n",
    "info = raw.info\n",
    "\n",
    "folder_name = Path.cwd().parent / \"data\" / \"dataframes\" / \"sensor\"\n",
    "subject_ids = []\n",
    "for file in sorted(os.listdir(folder_name)):\n",
    "    if file.endswith(\".pkl\"):\n",
    "        subject_ids.append(file[:5])\n",
    "subject_ids = list(np.unique(np.array(subject_ids)))\n",
    "# subjects_to_drop = [\"3dx2e\", \"6sjul\", \"musky\", \"8kmc7\", \"cmh15\", \"uvxfg\", \"2fjeu\", \"dws0m\", \"gigcm\"]\n",
    "\n",
    "protocols = [\"0.1Hz\", \"1Hz\", \"10Hz\", \"20Hz\"][3:4]\n",
    "hemis = [\"left\", \"right\"]\n",
    "franges = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "combs = product(protocols, hemis, franges)\n",
    "\n",
    "for protocol, hemi, frange in combs:\n",
    "    subjects_to_drop = subjects_to_drop_dict[f\"{hemi}_{protocol[:-2]} Hz\"] \n",
    "    x1, x2 = [], []\n",
    "    for subject_id in subject_ids:\n",
    "        if subject_id not in subjects_to_drop:\n",
    "            fname_pre = folder_name / f\"{subject_id}_{protocol}_{hemi}_pre.pkl\"\n",
    "            fname_post = folder_name / f\"{subject_id}_{protocol}_{hemi}_post.pkl\"\n",
    "\n",
    "            with open(fname_pre, \"rb\") as fpre:\n",
    "                dict_pre = pickle.load(fpre)\n",
    "            with open(fname_post, \"rb\") as fpost:\n",
    "                dict_post = pickle.load(fpost)\n",
    "\n",
    "            x1.append(dict_pre[frange].mean(axis=0))\n",
    "            x2.append(dict_post[frange].mean(axis=0))\n",
    "\n",
    "    X = np.array(x2) - np.array(x1)\n",
    "    # t_values, p_values, H0 = permutation_t_test(X=X, n_permutations=10000)\n",
    "    T0, p_values = ttest_ind(np.array(x1), np.array(x2))\n",
    "    \n",
    "    evoked = mne.EvokedArray(-np.log10(p_values)[:, np.newaxis], info, tmin=0.0)\n",
    "    mask = p_values[:, np.newaxis] <= 0.05\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    evoked.plot_topomap(\n",
    "        ch_type=\"eeg\",\n",
    "        times=[0],\n",
    "        scalings=1,\n",
    "        colorbar=False,\n",
    "        time_format=None,\n",
    "        cmap=None,\n",
    "        vlim=(0, np.max),\n",
    "        units=\"log10(t)\",\n",
    "        cbar_fmt=\"%0.1f\",\n",
    "        mask=mask,\n",
    "        size=3,\n",
    "        show_names=False,\n",
    "        time_unit=\"s\",\n",
    "        axes=ax\n",
    "    )\n",
    "    ax.set_title(f\"{protocol}_{hemi}_{frange}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation of gamma change and Tinnitus change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/Users/payamsadeghishabestari/codes/regTMS/data/behavioral_data/TL_data.xlsx\"\n",
    "subjects_to_drop = [\"3dx2e\", \"6sjul\", \"musky\", \"8kmc7\", \"cmh15\", \"uvxfg\", \"2fjeu\", \"dws0m\", \"gigcm\"]\n",
    "df_tl = pd.read_excel(fname)\n",
    "df_tl_sub = df_tl.query('ID != @subjects_to_drop & protcol == \"20 Hz\" & hemisphere == \"right\"')\n",
    "df_tl_sub['pre_avg'] = df_tl.filter(like='pre').mean(axis=1)\n",
    "df_tl_sub['post_avg'] = df_tl.filter(like='post').mean(axis=1)\n",
    "df_tl_sub[\"diff_TL\"] = df_tl_sub['pre_avg'] - df_tl_sub['post_avg']\n",
    "df_tl_sub = df_tl_sub.rename(columns={'ID': 'subject_ID'})\n",
    "df_tl_diff = df_tl_sub[[\"subject_ID\", \"diff_TL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load power in labels and add whole brain activation\n",
    "dfs_list = []\n",
    "folder_name = Path.cwd().parent / \"data\" / \"dataframes\" / \"powers\"\n",
    "for file in tqdm(sorted(os.listdir(folder_name))):\n",
    "    if file.endswith(\".csv\"):\n",
    "        fname = folder_name / file\n",
    "        df = pd.read_csv(fname, index_col=[0])\n",
    "        \n",
    "        ## add whole brain power\n",
    "        df1s_list = []\n",
    "        for frange in [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]:\n",
    "            for hemi in [\"lh\", \"rh\"]:\n",
    "                df1 = df[df[\"frequency_band\"] == frange]\n",
    "                df1 = df1[df1['brain_label'].str.contains(f'-{hemi}', case=False, na=False)]\n",
    "                power_hemi = df1[\"power\"].sum()\n",
    "                keys = list(df.columns)\n",
    "                values = [df1[key].unique()[0] for key in keys[:-2]]\n",
    "                values.append([f\"whole-{hemi}\"])\n",
    "                values.append([power_hemi])\n",
    "                new_row = dict(zip(keys, values))\n",
    "                df_new_row = pd.DataFrame(new_row)\n",
    "                df1 = pd.concat([df1, df_new_row])\n",
    "                df1s_list.append(df1)\n",
    "        df_updated = pd.concat(df1s_list)\n",
    "        dfs_list.append(df_updated)\n",
    "        \n",
    "dfs = pd.concat(dfs_list)\n",
    "df_eeg = dfs.reset_index().drop(columns=[\"index\", \"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_list = []\n",
    "bls = [\"frontalpole-rh\", \"lateralorbitofrontal-rh\", \"medialorbitofrontal-lh\", \"medialorbitofrontal-rh\", \"rostralanteriorcingulate-rh\"]\n",
    "for bl in bls:\n",
    "    df_sub = df_eeg.query(f'subject_ID != @subjects_to_drop & hemisphere == \"right\" & protocol == \"20 Hz\" & frequency_band == \"gamma\" & brain_label == \"{bl}\"')\n",
    "    df_pivot = df_sub.pivot(index='subject_ID', columns='run', values='power')\n",
    "    df_pivot['power_difference'] = df_pivot['post'] - df_pivot['pre']\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "    df_eeg_diff = df_pivot[[\"subject_ID\", \"power_difference\"]]\n",
    "    df_corr = pd.merge(df_eeg_diff, df_tl_diff, on='subject_ID', how='inner')\n",
    "    df_corr[\"brain_label\"] = [bl] * len(df_corr)\n",
    "    dfs_list.append(df_corr)\n",
    "df_corr = pd.concat(dfs_list)\n",
    "pal = sns.cubehelix_palette(2, rot=-.25, light=.7, as_cmap=False)\n",
    "sns.lmplot(data=df_corr, x=\"diff_TL\", y=\"power_difference\", col=\"brain_label\", palette=pal, scatter_kws={\"s\": 30, \"alpha\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
